{
  "description": "An example fixed token length chunker pipeline with letter tokenizer",
  "processors" : [
    {
      "text_chunking": {
        "field_map": {
          "body": "body_chunk"
        },
        "algorithm": {
          "fixed_token_length": {
            "token_limit": 10,
            "tokenizer": "letter"
          }
        }
      }
    }
  ]
}

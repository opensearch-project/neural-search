# TorchServe Configuration for Semantic Highlighter
# Optimized for CPU deployment

# Basic configuration
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# Model store
model_store=model_store
load_models=semantic_highlighter.mar

# CPU optimization settings
default_workers_per_model=4
job_queue_size=100
batch_size=8
max_batch_delay=50

# Disable CUDA for CPU-only deployment
disable_token_authorization=true
enable_metrics_api=true

# Memory settings for CPU
max_request_size=67108864
max_response_size=67108864

# Thread settings for CPU optimization
number_of_netty_threads=8
netty_client_threads=8
